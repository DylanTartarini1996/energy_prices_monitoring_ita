{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import subprocess\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "from typing import Tuple, Mapping, Sequence\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GasPrices:\n",
    "    \"\"\"\n",
    "    Makes use of the yfinance python module\n",
    "    to scrape natural gas prices from the TTF market.\n",
    "    \"\"\"\n",
    "\n",
    "    # def __init__(self) -> None:\n",
    "    #     pass\n",
    "\n",
    "    def get_data() -> pd.DataFrame:\n",
    "        symbol = \"TTF=F\"\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        gas_prices = ticker.history(\n",
    "            interval=\"1wk\",\n",
    "            start=\"2005-01-01\",\n",
    "            end=None,\n",
    "            actions=True,\n",
    "            auto_adjust=True,\n",
    "            back_adjust=False,\n",
    "        )\n",
    "\n",
    "        gas_prices.index = pd.to_datetime(gas_prices.index)\n",
    "        gas_prices.index = gas_prices.index.date\n",
    "        gas_prices = gas_prices[[\"Close\"]]\n",
    "        gas_prices = gas_prices.rename(columns={\"Close\": \"GAS NATURALE\"})\n",
    "\n",
    "        return gas_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def get_data(path: str) -> pd.DataFrame:\n",
    "        data = pd.read_csv(path, index_col=0)\n",
    "        return data\n",
    "\n",
    "    def preprocessing(data: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns data with index and frequency of index set\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.DataFrame\n",
    "\n",
    "        col: str\n",
    "            name of the column that will be kept\n",
    "        \"\"\"\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        data = data[col]\n",
    "        data = data.div(1000)\n",
    "        data.index.freq = pd.infer_freq(data.index)\n",
    "        return data\n",
    "\n",
    "    def train_test_split_series(data: pd.DataFrame, n_test: int) -> pd.DataFrame:\n",
    "        return data.iloc[:-n_test], data.iloc[-n_test:]\n",
    "\n",
    "    def train_test_split_df(data: pd.DataFrame, n_test: int) -> pd.DataFrame:\n",
    "        return data.iloc[:-n_test], data.iloc[-n_test:]\n",
    "\n",
    "    def series_to_supervised(\n",
    "        data: pd.Series, n_in: int = 1, dropnan: bool = True\n",
    "    ) -> np.array:\n",
    "        \"\"\"\n",
    "        Converts a sequence of numbers, i.e. a univariate time series, into a matrix\n",
    "        with one array (series at time t) plus one more array for each n_in\n",
    "        (lags at times t-1, t-2, .., t-n_in).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.Series\n",
    "\n",
    "        n_in: int\n",
    "            number of lags to create from the original series.\n",
    "            For each lag required, one more column will be added,\n",
    "            at the cost of one row of observations.\n",
    "\n",
    "        dropnan: bool\n",
    "\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(data)\n",
    "        cols = list()\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "        cols.append(df)\n",
    "        # put it all together\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        # drop rows with NaN values (in particular the first and the last rows)\n",
    "        if dropnan:\n",
    "            agg.dropna(inplace=True)\n",
    "\n",
    "        return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBForecaster(XGBRegressor):\n",
    "    \"\"\"\n",
    "    XGBoost model class used for univariate or multivariate forecasting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        #self.xgb = XGBRegressor()\n",
    "\n",
    "    def fit(\n",
    "            self, \n",
    "            model: XGBRegressor, \n",
    "            train_ensamble: pd.DataFrame\n",
    "            ) -> XGBRegressor:\n",
    "        \"\"\"\n",
    "        Trains an XGBRegressor on a TimeSeries Dataset\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        model: XGBRegressor\n",
    "            a fitted instance of the XGBRegressor\n",
    "        \"\"\"\n",
    "        data = np.asarray(train_ensamble)\n",
    "        X, y = data[:, :-1], data[:, -1]\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def forecast(self, \n",
    "                 model: XGBRegressor, \n",
    "                 row_just_before: int, \n",
    "                 steps_ahead: int\n",
    "        ) -> list:\n",
    "        \"\"\"\n",
    "            Rolling prediction with the model_fitted for predicting n=steps_ahead new instances.\n",
    "            This instances will immediately follow row_just_before, which is the last row of the dataframe available\n",
    "        \"\"\"\n",
    "        row_just_before = np.asarray(row_just_before)[1:]\n",
    "        current_row = row_just_before.reshape(1, -1)\n",
    "        forecast = []\n",
    "        for _ in range(steps_ahead):\n",
    "            pred = model.predict(current_row)\n",
    "            forecast.append(pred[0])\n",
    "            current_row = np.concatenate((current_row[0][1:], pred)).reshape(1, -1)\n",
    "        return forecast\n",
    "\n",
    "    def grid_search(\n",
    "            self, \n",
    "            parameters: Mapping, \n",
    "            n_folds: int, \n",
    "            train_df: pd.DataFrame, \n",
    "            test_size: int, \n",
    "            n_jobs: int =1, \n",
    "            verbose: int =0\n",
    "        ) -> Tuple[XGBRegressor, list]:\n",
    "        # model = self\n",
    "        self.grid = GridSearchCV(\n",
    "            self, parameters, cv=n_folds, n_jobs=n_jobs, verbose=verbose\n",
    "        )\n",
    "        self.grid = self.fit(self, model=self.grid, train_ensamble=train_df)\n",
    "        predictions = self.forecast(\n",
    "            self, \n",
    "            model=self.grid,\n",
    "            row_just_before=train_df.iloc[-1, :], \n",
    "            steps_ahead=test_size\n",
    "        )\n",
    "        return self.grid, predictions\n",
    "\n",
    "    def prepare_data(\n",
    "            self,\n",
    "            data: pd.DataFrame,\n",
    "            col: str, \n",
    "            frac: float\n",
    "        ) -> None:   \n",
    "            # ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "            Creates an experiment run for the model to be trained and preprocess the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: pd.DataFrame\n",
    "            data to use for training.\n",
    "        col: str\n",
    "            column to be kept in the data\n",
    "        frac: float\n",
    "            percentage of data to hold out for testing the model.\n",
    "\n",
    "        \"\"\"\n",
    "        self.data = Preprocessing.preprocessing(data, col)\n",
    "\n",
    "        self.train, self.test = Preprocessing.train_test_split_df(\n",
    "            data=self.data, \n",
    "            n_test=round(len(data) * frac)\n",
    "        )\n",
    "\n",
    "        self.proc_training_data = Preprocessing.series_to_supervised(\n",
    "            data=self.train, \n",
    "            n_in=1, \n",
    "            dropnan=True\n",
    "        )\n",
    "        self.proc_testing_data = Preprocessing.series_to_supervised(\n",
    "            data=self.test, \n",
    "            n_in=1, \n",
    "            dropnan=False\n",
    "        )\n",
    "        \n",
    "    def train_model(\n",
    "            self,\n",
    "            experiment_name: str, \n",
    "        ) -> None:\n",
    "        # prepare train and test data\n",
    "        self.proc_testing_data.fillna(self.proc_training_data.iloc[-1, -1])\n",
    "        X_train = self.proc_training_data.iloc[:, :-1].values\n",
    "        X_test = self.proc_testing_data.iloc[:, :-1].values\n",
    "        y_train = self.proc_training_data.iloc[:, -1].values\n",
    "        y_test = self.proc_testing_data.iloc[:, -1].values\n",
    "\n",
    "        frac = round((len(y_test)/len(self.data)), 2)\n",
    "        \n",
    "        # n-folds\n",
    "        effective_df_length = len(self.proc_training_data) - len(self.proc_testing_data)\n",
    "        max_folds = effective_df_length // len(self.proc_testing_data)\n",
    "        n_folds = min(max_folds, 10)\n",
    "\n",
    "        # Create the experiment if it does not exist\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            mlflow.create_experiment(experiment_name)\n",
    "            experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        # enable auto logging\n",
    "        mlflow.xgboost.autolog()\n",
    "        # start experiment run\n",
    "        with mlflow.start_run(experiment_id=experiment.experiment_id):\n",
    "            mlflow.log_param(key=\"pct_data_for_training\", value=(1 - frac))\n",
    "            mlflow.log_param(key=\"pct_data_for_testing\", value=(frac))\n",
    "            # log the script\n",
    "            # mlflow.log_artifact(__file__)\n",
    "\n",
    "            # Get current commit hash\n",
    "            commit_hash = (\n",
    "                 subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])\n",
    "                 .strip()\n",
    "                 .decode(\"utf-8\")\n",
    "            )\n",
    "            # Log Git commit hash as a parameter\n",
    "            # mlflow.log_param(\"commit_hash\", commit_hash)\n",
    "\n",
    "            parameters_xgb = {\n",
    "                \"gamma\": [0, 30, 100, 200],\n",
    "                \"eta\": [0.3, 0.03, 0.003],\n",
    "                \"max_depth\": [6, 12, 30],\n",
    "            }\n",
    "            self.xgb_grid, self.predictions_xgb = XGBForecaster.grid_search(\n",
    "                self,\n",
    "                parameters=parameters_xgb,\n",
    "                n_folds=n_folds,\n",
    "                train_df=self.proc_training_data,\n",
    "                test_size=len(self.proc_testing_data),\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "            )\n",
    "            mae = mean_absolute_error(y_test, self.predictions_xgb)\n",
    "            mape = mean_absolute_percentage_error(y_test, self.predictions_xgb)\n",
    "\n",
    "            # log metrics\n",
    "            mlflow.log_metrics({\"MAE\": mae, \"MAPE\": mape})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBForecaster(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;reg:squarederror&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBForecaster</label><div class=\"sk-toggleable__content\"><pre>XGBForecaster(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;reg:squarederror&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBForecaster(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='reg:squarederror', predictor=None, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBForecaster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_prices = GasPrices.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAS NATURALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>18.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>18.309999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>19.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>18.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>20.455000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GAS NATURALE\n",
       "2017-10-23     18.150000\n",
       "2017-10-30     18.309999\n",
       "2017-11-06     19.820000\n",
       "2017-11-13     18.950001\n",
       "2017-11-20     20.455000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = XGBForecaster()\n",
    "\n",
    "experiment_name = \"gas_model_nbk\"\n",
    "\n",
    "frac = 0.2\n",
    "\n",
    "forecaster.prepare_data(\n",
    "        data=gas_prices,\n",
    "        col=\"GAS NATURALE\",\n",
    "        frac=frac\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAS NATURALE</th>\n",
       "      <th>GAS NATURALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.018310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.019820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.018950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.020455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27</th>\n",
       "      <td>0.020455</td>\n",
       "      <td>0.020790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GAS NATURALE  GAS NATURALE\n",
       "2017-10-30      0.018150      0.018310\n",
       "2017-11-06      0.018310      0.019820\n",
       "2017-11-13      0.019820      0.018950\n",
       "2017-11-20      0.018950      0.020455\n",
       "2017-11-27      0.020455      0.020790"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.proc_training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got multiple values for argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m forecaster\u001b[39m.\u001b[39;49mtrain_model(experiment_name\u001b[39m=\u001b[39;49mexperiment_name)\n",
      "Cell \u001b[0;32mIn[36], line 152\u001b[0m, in \u001b[0;36mXGBForecaster.train_model\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Log Git commit hash as a parameter\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m# mlflow.log_param(\"commit_hash\", commit_hash)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m parameters_xgb \u001b[39m=\u001b[39m {\n\u001b[1;32m    148\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m200\u001b[39m],\n\u001b[1;32m    149\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39meta\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.3\u001b[39m, \u001b[39m0.03\u001b[39m, \u001b[39m0.003\u001b[39m],\n\u001b[1;32m    150\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m6\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m30\u001b[39m],\n\u001b[1;32m    151\u001b[0m }\n\u001b[0;32m--> 152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxgb_grid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions_xgb \u001b[39m=\u001b[39m XGBForecaster\u001b[39m.\u001b[39;49mgrid_search(\n\u001b[1;32m    153\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    154\u001b[0m     parameters\u001b[39m=\u001b[39;49mparameters_xgb,\n\u001b[1;32m    155\u001b[0m     n_folds\u001b[39m=\u001b[39;49mn_folds,\n\u001b[1;32m    156\u001b[0m     train_df\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproc_training_data,\n\u001b[1;32m    157\u001b[0m     test_size\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproc_testing_data),\n\u001b[1;32m    158\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    159\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    161\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions_xgb)\n\u001b[1;32m    162\u001b[0m mape \u001b[39m=\u001b[39m mean_absolute_percentage_error(y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictions_xgb)\n",
      "Cell \u001b[0;32mIn[36], line 59\u001b[0m, in \u001b[0;36mXGBForecaster.grid_search\u001b[0;34m(self, parameters, n_folds, train_df, test_size, n_jobs, verbose)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrid_search\u001b[39m(\n\u001b[1;32m     47\u001b[0m         \u001b[39mself\u001b[39m, \n\u001b[1;32m     48\u001b[0m         parameters: Mapping, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[XGBRegressor, \u001b[39mlist\u001b[39m]:\n\u001b[1;32m     55\u001b[0m     \u001b[39m# model = self\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m     57\u001b[0m         \u001b[39mself\u001b[39m, parameters, cv\u001b[39m=\u001b[39mn_folds, n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose\n\u001b[1;32m     58\u001b[0m     )\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrid, train_ensamble\u001b[39m=\u001b[39;49mtrain_df)\n\u001b[1;32m     60\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforecast(\n\u001b[1;32m     61\u001b[0m         \u001b[39mself\u001b[39m, \n\u001b[1;32m     62\u001b[0m         model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid,\n\u001b[1;32m     63\u001b[0m         row_just_before\u001b[39m=\u001b[39mtrain_df\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :], \n\u001b[1;32m     64\u001b[0m         steps_ahead\u001b[39m=\u001b[39mtest_size\n\u001b[1;32m     65\u001b[0m     )\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid, predictions\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() got multiple values for argument 'model'"
     ]
    }
   ],
   "source": [
    "forecaster.train_model(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = forecaster.train_model(\n",
    "    experiment_name=experiment_name,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(test_data.tail(1))[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.asarray(test_data.tail(1))[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, last_data_row: np.array, n_steps:int, ) -> list:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
